\section{介绍}
\miniframesoff

%\subsection{课题背景和意义}
\frame
{
\frametitle{课题背景和意义}
\begin{block}{增量梯度方法}
  \begin{itemize}
    \item 机器学习领域中应用最广泛的一类优化方法
    \item 每次迭代只需计算少量的数据样本所对应的目标函数梯度
    \item 优点：迭代速度快、计算和存储复杂度较低、扩展性好等等
    \item 按抽取数据样本的方式可分为两类：
      \begin{itemize}
        \item 随机方法——随机梯度下降（SGD）及其变种
        \item \textbf{确定性方法}
      \end{itemize}
  \end{itemize}
\end{block}

\pause

\begin{block}{选题意义}
  \begin{itemize}
    \item 理论意义：有助于理解一般增量梯度方法的收敛性质
    \item 实践意义：有助于提高机器学习算法的实用性和可扩展性
  \end{itemize}
\end{block}
}

\frame
{
\frametitle{研究现状}
\footnotesize
问题：$\underset{w \in \mathbb{R}^d}{\mathrm{min}} \ F(w) \coloneqq \frac{1}{N} \sum_{i=1}^N f_i(w) $， \pause 增量梯度方法：$w_{t+1} = w_t - \eta_t \ g(w_t, i_t)$ \\~\\
\pause 其中$g$：真实梯度$\nabla F(w_t)$的估计量，$i_t$：第$t$次迭代选择的数据样本

\pause

\begin{block}{}
选择数据样本：
\begin{itemize}
    \item 随机采样
    \begin{itemize}
        \item \alert<6>{可放回采样}：均匀采样、重要性采样、自适应采样
        \item 不可放回采样：随机重排
    \end{itemize}
    \item 确定性顺序
\end{itemize}
\end{block}

\pause

\begin{block}{}
设计梯度估计方式：
\begin{itemize}
    \item 单独近似：$g(w_t, i_t) = \nabla f_{i_t}(w_t)$
    \item \alert<6>{平均近似}：$g(w_t, i_t) = \frac{1}{N}\sum_{i=1}^N\nabla f_i(w_{\tau_i})$
    % \tikz[remember picture] \node[coordinate,yshift=0.5em] (n1) {};
    \item \alert<6>{混合近似}：$g(w_t, i_t) = \nabla f_{i_t}(w_t) - \nabla f_{i_t}(\tilde{w}) + \nabla F(\tilde{w})$
    \item \alert<6>{……}
    % \tikz[remember picture] \node[coordinate] (n2) {};
\end{itemize}
\end{block}

% \only<5>{\alert{
% \begin{tikzpicture}[overlay,remember picture]
%     \path (n2) -| node[coordinate] (n3) {} (n1);
%     \draw[thick,decorate,decoration={brace,amplitude=3pt}]
%           (n1) -- (n3) node[midway, right=4pt] {降方差方法};
% \end{tikzpicture}}}
}

\frame
{
\frametitle{本文工作}
\begin{itemize}
  \item 提出了“基于快照的增量梯度方法”（SIG）及其加速变种 \vspace*{1em}
  \item 证明了所提出的SIG方法达到线性收敛 \vspace*{1em}
  \item 将SIG算法推广到更一般的单调算子零点问题上，证明了在这一类问题上同样达到线性收敛
\end{itemize}
}

\miniframeson
